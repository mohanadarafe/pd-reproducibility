{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb3f3e9",
   "metadata": {},
   "source": [
    "# Machine Learning pipeline\n",
    "\n",
    "In this notebook, we go through the machine learning pipeline to reproduce Lydia Chougar's paper. The following sections will be covered:\n",
    "\n",
    "1 - Convert CSV to DataFrame\n",
    "\n",
    "2 - Normalize\n",
    "\n",
    "3 - Train and predict models\n",
    "\n",
    "4 - Cross Validation\n",
    "\n",
    "5 - Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc488c91",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42237f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, utils, sys\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7ea21",
   "metadata": {},
   "source": [
    "# Convert CSV to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b341a",
   "metadata": {},
   "source": [
    "Converts data from CSV to DataFrame and applies any function. \n",
    "- \"combine\": sums all Left and Right regions into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac891096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(csvFileName: str, ROI: [], heuristic = None, getDf = False):\n",
    "    '''\n",
    "    The following function will sanitize data and build a numpy array with X ROI's volumes and y being the class [NC, PD]\n",
    "    @csvFileName: input volumes csv\n",
    "    @ROI: regions of interests desired\n",
    "    @heuristic: function key\n",
    "    '''\n",
    "    df = pd.read_csv(csvFileName)\n",
    "    df = utils.remove_unwanted_columns(df, ROI)\n",
    "    \n",
    "    if heuristic == \"combine\":\n",
    "        df = utils.combine_left_right_vol(df)\n",
    "        \n",
    "    if (getDf):\n",
    "        return df\n",
    "    else:\n",
    "        df = df.drop(\"subjectId\", 1)\n",
    "        \n",
    "    arr = df.values\n",
    "    X = arr[:, :-1]\n",
    "    y = utils.convert_Y(arr[:, -1])\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b76c0a",
   "metadata": {},
   "source": [
    "Test *get_data()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dba8c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/Desktop/research/pd-reproducibility/ml/utils.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop(column, 1)\n",
      "/home/mohanad/anaconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "ROI = [\n",
    "      \"subjectId\", \"class\",\n",
    "      \"Left-Putamen\", \"Right-Putamen\", \n",
    "      \"Right-Caudate\", \"Left-Caudate\", \n",
    "      \"Right-Thalamus-Proper\", \"Left-Thalamus-Proper\", \n",
    "      \"Left-Pallidum\", \"Right-Pallidum\", \n",
    "      \"Left-Cerebellum-Cortex\", \"Right-Cerebellum-Cortex\", \"lhCortexVol\", \"rhCortexVol\", \"CortexVol\",\n",
    "      \"Left-Cerebellum-White-Matter\", \"Right-Cerebellum-White-Matter\",\n",
    "      \"CerebralWhiteMatterVol\", \n",
    "      \"3rd-Ventricle\", \"4th-Ventricle\"\n",
    "   ]\n",
    "X, y = get_data(\"volumes.csv\", ROI, \"combine\")\n",
    "df = get_data(\"volumes.csv\", ROI, \"combine\", getDf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909a3d1",
   "metadata": {},
   "source": [
    "# 2. [Normalize](#normal)\n",
    "\n",
    "In this section, normalization of the data using \"Normalization 1\" and \"Normaliztion 2\" techniques are implemented. \n",
    "\n",
    "Normalization 1:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}{\\sigma \\;of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}$$\n",
    "\n",
    "Normalization 2:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}{\\sigma \\;of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12cafd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize1(data, mean, std):\n",
    "    df = pd.DataFrame(data=data)\n",
    "\n",
    "    if mean is None and std is None:\n",
    "        mean = df.mean(axis=0)\n",
    "        std = testDf.std(axis=0)\n",
    "        normalizedDf = (df - mean)/std\n",
    "        return normalizedDf, mean, std\n",
    "\n",
    "    normalizedDf = (df - mean)/std\n",
    "    return normalizedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a4221f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  4.24264069, -0.28284271],\n",
       "       [ 1.41421356,  5.65685425,  1.13137085]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing normalization1\n",
    "trainDf = pd.DataFrame(np.array([[1, 2, 3], [3, 4, 7]]),columns=['a', 'b', 'c'])\n",
    "testDf = pd.DataFrame(np.array([[2, 6, 4], [3, 7, 9]]),columns=['a', 'b', 'c'])\n",
    "normTrainDf, trainMean, trainStd = normalize1(trainDf, None, None)\n",
    "normTestDf = normalize1(testDf, trainMean, trainStd)\n",
    "normTestDf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c572ae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4         5         6   \\\n",
      "0   -1.254627  0.027858 -0.489725 -0.341841 -0.731373 -1.033358 -0.373735   \n",
      "1    0.301883  2.070251  1.624695  0.607634 -0.196809   0.36249  1.738754   \n",
      "2    0.735996  0.456097  0.450533  0.244247  0.843845  1.022511  0.947571   \n",
      "3     0.00614  1.704153  0.818538 -0.533545 -0.242789 -0.858736 -0.721767   \n",
      "4   -0.562185  0.003687 -1.088977 -0.984206 -0.765684 -0.124842  0.707845   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "210  2.284984  0.610996 -0.301629  0.020009  2.710298 -0.453807 -0.530935   \n",
      "211   0.95038  1.679982  0.072571  0.006177  0.756519 -0.563408  0.042006   \n",
      "212  0.874365  -0.25656 -0.246639  -0.31144 -0.006132  0.662485  1.041801   \n",
      "213  0.600595  1.061291  2.132112  1.529245  -0.15697 -0.271943  0.639098   \n",
      "214    4655.8    8916.2    6840.7  102689.1   31238.7    1666.8    1258.1   \n",
      "\n",
      "                7              8             9         10  \n",
      "0        -0.591752       -0.62927     -0.611802 -1.036897  \n",
      "1          0.78846       1.237547      1.012968  0.467241  \n",
      "2         0.718528       0.477829      0.601005  1.452707  \n",
      "3         0.055157       0.133278      0.094009 -0.611987  \n",
      "4        -0.546413      -0.687217      -0.61754 -1.224282  \n",
      "..             ...            ...           ...       ...  \n",
      "210      -0.247558      -0.202081     -0.225629  1.011519  \n",
      "211       -0.18905       0.009398     -0.091164  0.404083  \n",
      "212      -1.398829      -1.293641     -1.350139  -0.91466  \n",
      "213       2.834724       2.968065      2.907782  0.968191  \n",
      "214  216814.479354  217215.692236  434030.17159  456889.0  \n",
      "\n",
      "[215 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/anaconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  if __name__ == '__main__':\n",
      "/home/mohanad/Desktop/research/pd-reproducibility/ml/utils.py:48: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean = queryDf.mean()\n",
      "/home/mohanad/Desktop/research/pd-reproducibility/ml/utils.py:49: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  std = queryDf.std()\n"
     ]
    }
   ],
   "source": [
    "def normalize2(data, ROI):\n",
    "    df = pd.DataFrame(data=data)\n",
    "    df_with_subjects = get_data(\"volumes.csv\", ROI, \"combine\", getDf=True)\n",
    "    metadata_df = utils.parse_metadata()\n",
    "    merged_df = pd.merge(df_with_subjects, metadata_df, on=[\"subjectId\"])\n",
    "    \n",
    "    stats = {}\n",
    "    for scanner in merged_df[\"scannerType\"].unique():\n",
    "        mean, std = utils.get_mean_and_stats(merged_df.drop(\"subjectId\",1), scanner)\n",
    "        stats[scanner] = {\n",
    "            \"mean\": mean.to_dict(),\n",
    "            \"std\": std.to_dict()\n",
    "        }\n",
    "        \n",
    "    for index in merged_df.index:\n",
    "        rowInfo = merged_df.iloc[index]\n",
    "        scanner = rowInfo[\"scannerType\"]\n",
    "        mean = list(stats[scanner][\"mean\"].values())\n",
    "        std = list(stats[scanner][\"std\"].values())\n",
    "        df.iloc[index] = (df.iloc[index]-mean)/std\n",
    "        \n",
    "    return df\n",
    "    \n",
    "normalize2DF = normalize2(X, ROI)\n",
    "print(normalize2DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52157a2b",
   "metadata": {},
   "source": [
    "# 3. [Train and predict models](#predict)\n",
    "\n",
    "In this section, we define four models being logisitc regression, SVM with linear and radial kernel and a random forest. As per the paper:\n",
    "\n",
    "_Using the scikit-learn package, four supervised\n",
    "machine learning algorithms were used: logistic regression, support vector machine (SVM) with a linear kernel, SVM with a radial basis function kernel, and\n",
    "random forest_ (Chougar et al.)\n",
    "\n",
    "Additionally, we will implement a stratified cross validation loop for hyperparameter tuning. As per the paper:\n",
    "\n",
    "_The cross-validation procedure on the training cohort included two nested loops: an outer loop with repeated stratified random splits with 50 repetitions evaluating the classification performances and an inner loop with 5 fold cross-validation used to optimize the hyperparameters of the algorithms_ (Chougar et al.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f25f2dd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9bd77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Utils\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a2481",
   "metadata": {},
   "source": [
    "## Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6b982c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, training_split):\n",
    "    '''\n",
    "    The following function splits the training and testing data sets\n",
    "    according to a split [0 - 1] passed.\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = training_split, random_state = 42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_model_score(model, X_train, y_train, X_test, y_test):\n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print(f'training score: {round(train_acc, 3)}')\n",
    "    print(f'testing score: {round(test_acc, 3)}')\n",
    "    return train_acc, test_acc\n",
    "\n",
    "def model(X, y, modelType, dataSplit, normalize, paramGrid):\n",
    "    # Define training, validation and test sets\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, dataSplit)\n",
    "    \n",
    "    # Setup CV\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=50)\n",
    "    \n",
    "    # Define model type\n",
    "    if modelType == \"SVM\":\n",
    "        clf = GridSearchCV(SVC(random_state=0), paramGrid, cv=cv)\n",
    "    elif modelType == \"RF\":\n",
    "        clf = GridSearchCV(RandomForestClassifier(random_state=0), paramGrid, cv=cv)\n",
    "    elif modelType == \"LR\":\n",
    "        clf = GridSearchCV(LogisticRegression(random_state=0), paramGrid, cv=cv)\n",
    "        \n",
    "    # Normalize model data\n",
    "    if normalize.__name__ == \"normalize1\":\n",
    "        X_grid_normalized, mean_train, std_train = normalize(X_train, None, None)\n",
    "        X_test_normalized = normalize(X_test, mean_train, std_train)\n",
    "        \n",
    "    # Fit and predict\n",
    "    model = clf.fit(X_grid_normalized, y_train)\n",
    "    train_acc, test_acc = get_model_score(X_grid_normalized, y_grid, X_test_normalized, y_test)\n",
    "    print(f'Best model params: {model.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91094b77",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4225c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [1.0, 10.0, 100.0, 1000.0],\n",
    "    'gamma': [0.01, 0.10, 1.00, 10.00]\n",
    "}\n",
    "for kernelType in [\"linear\", \"rbf\"]:\n",
    "    param_grid[\"kernel\"] = kernelType\n",
    "#     model(X, y, \"SVM\", 0.7, normalize1, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de088725",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb876216",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': [\"l1\", \"l2\", \"elasticnet\"],\n",
    "    'C': [1.0, 10.0, 100.0, 1000.0]\n",
    "}\n",
    "# model(X, y, \"LR\", 0.7, normalize1, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f48d25",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b70ad5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 4, 5, 10, 13],\n",
    "    'min_samples_leaf': [1, 2, 5, 8, 13]\n",
    "}\n",
    "# model(X, y, \"RF\", 0.7, normalize1, param_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
