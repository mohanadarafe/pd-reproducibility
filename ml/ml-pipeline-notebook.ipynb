{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb3f3e9",
   "metadata": {},
   "source": [
    "# Machine Learning pipeline\n",
    "\n",
    "In this notebook, we go through the machine learning pipeline to reproduce Lydia Chougar's paper. The following sections will be covered:\n",
    "\n",
    "1 - Convert CSV to DataFrame\n",
    "\n",
    "2 - Normalize\n",
    "\n",
    "3 - Train and predict models\n",
    "\n",
    "4 - Cross Validation\n",
    "\n",
    "5 - Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc488c91",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42237f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, utils, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7ea21",
   "metadata": {},
   "source": [
    "# Convert CSV to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b341a",
   "metadata": {},
   "source": [
    "Converts data from CSV to DataFrame and applies any function. \n",
    "- \"combine\": sums all Left and Right regions into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac891096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(csvFileName: str, ROI: [], heuristic = None):\n",
    "    '''\n",
    "    The following function will sanitize data and build a numpy array with X ROI's volumes and y being the class [NC, PD]\n",
    "    @csvFileName: input volumes csv\n",
    "    @ROI: regions of interests desired\n",
    "    @heuristic: function key\n",
    "    '''\n",
    "    df = pd.read_csv(csvFileName)\n",
    "    df = utils.remove_unwanted_columns(df, ROI)\n",
    "    \n",
    "    if heuristic == \"combine\":\n",
    "        df = utils.combine_left_right_vol(df)\n",
    "        \n",
    "    arr = df.values\n",
    "    X = arr[:, :-1]\n",
    "    y = utils.convert_Y(arr[:, -1])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b76c0a",
   "metadata": {},
   "source": [
    "Test *get_data()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dba8c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/Desktop/research/pd-reproducibility/ml/utils.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop(column, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4805.9, 10689.0, 8204.3, ..., 260137.320394, 521837.72897,\n",
       "        541416.0],\n",
       "       [4025.5, 9543.6, 6856.3, ..., 227892.928374, 453029.527784,\n",
       "        459966.0],\n",
       "       [4416.1, 9640.2, 6508.2, ..., 226647.385438, 452146.451741,\n",
       "        467340.0],\n",
       "       ...,\n",
       "       [3714.0, 9247.0, 6964.6, ..., 242313.526846, 483537.306049,\n",
       "        427627.0],\n",
       "       [4367.5, 10956.0, 6407.2, ..., 251437.424595, 503486.026837,\n",
       "        453074.0],\n",
       "       [4183.0, 9857.7, 6906.6, ..., 256543.358332, 508441.662564,\n",
       "        508866.0]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROI = [\n",
    "      \"class\",\n",
    "      \"Left-Putamen\", \"Right-Putamen\", \n",
    "      \"Right-Caudate\", \"Left-Caudate\", \n",
    "      \"Right-Thalamus-Proper\", \"Left-Thalamus-Proper\", \n",
    "      \"Left-Pallidum\", \"Right-Pallidum\", \n",
    "      \"Left-Cerebellum-Cortex\", \"Right-Cerebellum-Cortex\", \"lhCortexVol\", \"rhCortexVol\", \"CortexVol\",\n",
    "      \"Left-Cerebellum-White-Matter\", \"Right-Cerebellum-White-Matter\",\n",
    "      \"CerebralWhiteMatterVol\", \n",
    "      \"3rd-Ventricle\", \"4th-Ventricle\"\n",
    "   ]\n",
    "X, y = get_data(\"volumes.csv\", ROI, \"combine\")\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909a3d1",
   "metadata": {},
   "source": [
    "# 2. [Normalize](#normal)\n",
    "\n",
    "In this section, normalization of the data using \"Normalization 1\" and \"Normaliztion 2\" techniques are implemented. \n",
    "\n",
    "Normalization 1:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}{\\sigma \\;of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}$$\n",
    "\n",
    "Normalization 2:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}{\\sigma \\;of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e12cafd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize1(data, mean, std):\n",
    "    df = pd.DataFrame(data=data)\n",
    "\n",
    "    if mean is None and std is None:\n",
    "        mean = df.mean(axis=0)\n",
    "        std = testDf.std(axis=0)\n",
    "        normalizedDf = (df - mean)/std\n",
    "        return normalizedDf, mean, std\n",
    "\n",
    "    normalizedDf = (df - mean)/std\n",
    "    return normalizedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a4221f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>-0.282843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>1.131371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c\n",
       "0  0.000000  4.242641 -0.282843\n",
       "1  1.414214  5.656854  1.131371"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing normalization1\n",
    "trainDf = pd.DataFrame(np.array([[1, 2, 3], [3, 4, 7]]),columns=['a', 'b', 'c'])\n",
    "testDf = pd.DataFrame(np.array([[2, 6, 4], [3, 7, 9]]),columns=['a', 'b', 'c'])\n",
    "normTrainDf, trainMean, trainStd = normalize1(trainDf, None, None)\n",
    "normTestDf = normalize1(testDf, trainMean, trainStd)\n",
    "normTestDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62953f5",
   "metadata": {},
   "source": [
    "### TODO: Fetch metadata for every patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c572ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize2():\n",
    "    print(\"TODO - Unimplemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52157a2b",
   "metadata": {},
   "source": [
    "# 3. [Train and predict models](#predict)\n",
    "\n",
    "In this section, we define four models being logisitc regression, SVM with linear and radial kernel and a random forest. As per the paper:\n",
    "\n",
    "_Using the scikit-learn package, four supervised\n",
    "machine learning algorithms were used: logistic regression, support vector machine (SVM) with a linear kernel, SVM with a radial basis function kernel, and\n",
    "random forest_ (Chougar et al.)\n",
    "\n",
    "Additionally, we will implement a stratified cross validation loop for hyperparameter tuning. As per the paper:\n",
    "\n",
    "_The cross-validation procedure on the training cohort included two nested loops: an outer loop with repeated stratified random splits with 50 repetitions evaluating the classification performances and an inner loop with 5 fold cross-validation used to optimize the hyperparameters of the algorithms_ (Chougar et al.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f25f2dd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9bd77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Utils\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a2481",
   "metadata": {},
   "source": [
    "## Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6b982c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, training_split):\n",
    "    '''\n",
    "    The following function splits the training and testing data sets\n",
    "    according to a split [0 - 1] passed.\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = training_split, random_state = 42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_model_score(model, X_train, y_train, X_test, y_test):\n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print(f'training score: {round(train_acc, 3)}')\n",
    "    print(f'testing score: {round(test_acc, 3)}')\n",
    "    return train_acc, test_acc\n",
    "\n",
    "def model(X, y, modelType, dataSplit, normalize, paramGrid):\n",
    "    # Define training, validation and test sets\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, dataSplit)\n",
    "    \n",
    "    # Setup CV\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=50)\n",
    "    \n",
    "    # Define model type\n",
    "    if modelType == \"SVM\":\n",
    "        clf = GridSearchCV(SVC(random_state=0), paramGrid, cv=cv)\n",
    "    elif modelType == \"RF\":\n",
    "        clf = GridSearchCV(RandomForestClassifier(random_state=0), paramGrid, cv=cv)\n",
    "    elif modelType == \"LR\":\n",
    "        clf = GridSearchCV(LogisticRegression(random_state=0), paramGrid, cv=cv)\n",
    "        \n",
    "    # Normalize model data\n",
    "    if normalize.__name__ == \"normalize1\":\n",
    "        X_grid_normalized, mean_train, std_train = normalize(X_train, None, None)\n",
    "        X_test_normalized = normalize(X_test, mean_train, std_train)\n",
    "        \n",
    "    # Fit and predict\n",
    "    model = clf.fit(X_grid_normalized, y_grid)\n",
    "    train_acc, test_acc = get_model_score(X_grid_normalized, y_grid, X_test_normalized, y_test)\n",
    "    print(f'Best model params: {model.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91094b77",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4225c553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [1.0, 10.0, 100.0, 1000.0], 'gamma': [0.01, 0.1, 1.0, 10.0], 'kernel': 'linear'}\n",
      "{'C': [1.0, 10.0, 100.0, 1000.0], 'gamma': [0.01, 0.1, 1.0, 10.0], 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [1.0, 10.0, 100.0, 1000.0],\n",
    "    'gamma': [0.01, 0.10, 1.00, 10.00]\n",
    "}\n",
    "for kernelType in [\"linear\", \"rbf\"]:\n",
    "    param_grid[\"kernel\"] = kernelType\n",
    "#     model(X, y, \"SVM\", 0.7, normalize1, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de088725",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb876216",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': [\"l1\", \"l2\", \"elasticnet\"],\n",
    "    'C': [1.0, 10.0, 100.0, 1000.0]\n",
    "}\n",
    "# model(X, y, \"LR\", 0.7, normalize1, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f48d25",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ad5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 4, 5, 10, 13],\n",
    "    'min_samples_leaf': [1, 2, 5, 8, 13]\n",
    "}\n",
    "# model(X, y, \"RF\", 0.7, normalize1, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc918e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2eb8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b6bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
