{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15233c3d",
   "metadata": {},
   "source": [
    "# Machine Learning pipeline\n",
    "\n",
    "In this notebook, we go through the machine learning pipeline to reproduce Lydia Chougar's paper. The following sections will be covered:\n",
    "\n",
    "1 - Convert CSV to DataFrame\n",
    "\n",
    "2 - Normalize\n",
    "\n",
    "3 - Train and predict models\n",
    "\n",
    "4 - Cross Validation\n",
    "\n",
    "5 - Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e9a03",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4006ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, utils, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e47a9",
   "metadata": {},
   "source": [
    "# Convert CSV to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d5cb3b",
   "metadata": {},
   "source": [
    "Converts data from CSV to DataFrame and applies any function. \n",
    "- \"combine\": sums all Left and Right regions into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693e38e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(csvFileName: str, ROI: [], heuristic = None):\n",
    "    '''\n",
    "    The following function will sanitize data and build a numpy array with X ROI's volumes and y being the class [NC, PD]\n",
    "    @csvFileName: input volumes csv\n",
    "    @ROI: regions of interests desired\n",
    "    @heuristic: function key\n",
    "    '''\n",
    "    df = pd.read_csv(csvFileName)\n",
    "    df = utils.remove_unwanted_columns(df, ROI)\n",
    "    \n",
    "    if heuristic == \"combine\":\n",
    "        df = utils.combine_left_right_vol(df)\n",
    "        \n",
    "    arr = df.values\n",
    "    X = arr[:, :-1]\n",
    "    y = utils.convert_Y(arr[:, -1])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f343a3",
   "metadata": {},
   "source": [
    "Test *get_data()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b56d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3960.4, 8604.5, 6236.9, 12916.8, 104394.3, 27950.199999999997,\n",
       "         1987.7, 2656.4, 198898.000288, 200628.568064, 399526.568352,\n",
       "         402347.086652],\n",
       "        [3962.5, 9066.5, 6554.4, 15101.8, 84171.1, 31016.5, 1366.0,\n",
       "         1327.3, 213315.819602, 211745.893941, 425061.713542,\n",
       "         452280.825563],\n",
       "        [4608.3, 8298.6, 7397.2, 13759.7, 96178.0, 31029.0, 2021.7,\n",
       "         1337.2, 224162.804546, 230368.263921, 454531.068467,\n",
       "         443310.044391],\n",
       "        [3814.2, 9217.3, 6923.0, 12966.0, 101741.2, 28785.2, 786.0,\n",
       "         1407.4, 225090.539205, 228753.382537, 453843.921742,\n",
       "         405300.824822],\n",
       "        [3381.7, 8170.700000000001, 5873.1, 13135.5, 111484.70000000001,\n",
       "         33025.7, 2095.3, 1511.8, 223562.648811, 228791.484653,\n",
       "         452354.133464, 382072.850614]], dtype=object),\n",
       " array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROI = [\n",
    "      \"class\",\n",
    "      \"Left-Putamen\", \"Right-Putamen\", \n",
    "      \"Right-Caudate\", \"Left-Caudate\", \n",
    "      \"Right-Thalamus-Proper\", \"Left-Thalamus-Proper\", \n",
    "      \"Left-Pallidum\", \"Right-Pallidum\", \n",
    "      \"Left-Cerebellum-Cortex\", \"Right-Cerebellum-Cortex\", \"lhCortexVol\", \"rhCortexVol\", \"CortexVol\",\n",
    "      \"Left-Cerebellum-White-Matter\", \"Right-Cerebellum-White-Matter\",\n",
    "      \"CerebralWhiteMatterVol\", \n",
    "      \"3rd-Ventricle\", \"4th-Ventricle\"\n",
    "   ]\n",
    "X, y = get_data(\"test_volumes.csv\", ROI, \"combine\")\n",
    "X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd1845e",
   "metadata": {},
   "source": [
    "# 2. [Normalize](#normal)\n",
    "\n",
    "In this section, normalization of the data using \"Normalization 1\" and \"Normaliztion 2\" techniques are implemented. \n",
    "\n",
    "Normalization 1:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}{\\sigma \\;of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}$$\n",
    "\n",
    "Normalization 2:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}{\\sigma \\;of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3f0d05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03805108, -0.16271336, -0.67986075, -0.80379434,  0.5246605 ,\n",
       "        -1.33655941,  0.66540423,  1.98313006, -1.80883225, -1.63646943,\n",
       "        -1.72283184, -0.55551598],\n",
       "       [ 0.04338534,  0.95894545, -0.08029465,  1.86064318, -1.68561903,\n",
       "         0.36318682, -0.5644739 , -0.63074384, -0.36861406, -0.70007485,\n",
       "        -0.55084518,  1.32953587],\n",
       "       [ 1.68379842, -0.90538745,  1.51124649,  0.22405664, -0.37333387,\n",
       "         0.37011596,  0.73266473, -0.61127401,  0.71490798,  0.86845759,\n",
       "         0.80170993,  0.99087932],\n",
       "       [-0.33331527,  1.32506265,  0.61576855, -0.74379877,  0.23469192,\n",
       "        -0.87369273, -1.711859  , -0.47321521,  0.80758083,  0.73243871,\n",
       "         0.77017195, -0.44400922],\n",
       "       [-1.43191957, -1.21590728, -1.36685964, -0.53710671,  1.29960047,\n",
       "         1.47694937,  0.87826395, -0.267897  ,  0.6549575 ,  0.73564799,\n",
       "         0.70179513, -1.32088999]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize1(data):\n",
    "    normalizedX = []\n",
    "    \n",
    "    for row in X:\n",
    "        normalizedRow = []\n",
    "        for columnIndex, variable in enumerate(row):\n",
    "            mean = np.mean(data[:, columnIndex])\n",
    "            std = np.std(data[:, columnIndex])\n",
    "            normalizedValue = (variable - mean)/std\n",
    "            normalizedRow.append(normalizedValue)        \n",
    "        normalizedX.append(normalizedRow)\n",
    "        \n",
    "    return np.array(normalizedX)\n",
    "            \n",
    "normalize1(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c98876e",
   "metadata": {},
   "source": [
    "### TODO: Fetch metadata for every patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e77475c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize2():\n",
    "    print(\"TODO - Unimplemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e7e1f",
   "metadata": {},
   "source": [
    "# 3. [Train and predict models](#predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc1998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
