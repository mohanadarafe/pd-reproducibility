{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning pipeline\n",
    "\n",
    "In this notebook, we go through the machine learning pipeline to reproduce Lydia Chougar's paper. The following sections will be covered:\n",
    "\n",
    "[1. Convert CSV to DataFrame](#data)\n",
    "\n",
    "[2. Normalize data](#normalize)\n",
    "\n",
    "[3. Define models](#models)\n",
    "\n",
    "[4. Training models](#training)\n",
    "\n",
    "[5. Results](#results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, utils, sys, os, json\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts data from CSV to DataFrame and applies any function. \n",
    "- \"combine\": sums all Left and Right regions into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(csvFileName: str, ROI: [], heuristic = None):\n",
    "    '''\n",
    "    The following function will sanitize data and build a numpy array with X ROI's volumes and y being the class [NC, PD]\n",
    "    @csvFileName: input volumes csv\n",
    "    @ROI: regions of interests desired\n",
    "    @heuristic: function key\n",
    "    '''\n",
    "    df = pd.read_csv(csvFileName)\n",
    "    df = utils.remove_unwanted_columns(df, ROI)\n",
    "    \n",
    "    if heuristic == \"combine\":\n",
    "        df = utils.combine_left_right_vol(df)\n",
    "        \n",
    "    cols = list(df.columns.values)\n",
    "    cols.pop(cols.index(\"subjectId\"))\n",
    "    df = df[[\"subjectId\"]+cols]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test *get_data()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectId</th>\n",
       "      <th>Pallidum</th>\n",
       "      <th>Putamen</th>\n",
       "      <th>Caudate</th>\n",
       "      <th>Cerebellum-Cortex</th>\n",
       "      <th>Cerebellum-White-Matter</th>\n",
       "      <th>3rd-Ventricle</th>\n",
       "      <th>4th-Ventricle</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3572</td>\n",
       "      <td>3234.8</td>\n",
       "      <td>9403.7</td>\n",
       "      <td>6425.5</td>\n",
       "      <td>101202.1</td>\n",
       "      <td>25991.9</td>\n",
       "      <td>809.7</td>\n",
       "      <td>1595.2</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3756</td>\n",
       "      <td>4021.1</td>\n",
       "      <td>11431.6</td>\n",
       "      <td>8336.5</td>\n",
       "      <td>112507.9</td>\n",
       "      <td>27906.7</td>\n",
       "      <td>1677.0</td>\n",
       "      <td>3021.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3768</td>\n",
       "      <td>4240.4</td>\n",
       "      <td>9828.9</td>\n",
       "      <td>7275.3</td>\n",
       "      <td>108180.9</td>\n",
       "      <td>31634.3</td>\n",
       "      <td>2087.1</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3369</td>\n",
       "      <td>3871.7</td>\n",
       "      <td>11068.1</td>\n",
       "      <td>7607.9</td>\n",
       "      <td>98919.4</td>\n",
       "      <td>27742.0</td>\n",
       "      <td>918.2</td>\n",
       "      <td>1360.3</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4004</td>\n",
       "      <td>3584.6</td>\n",
       "      <td>9379.7</td>\n",
       "      <td>5883.9</td>\n",
       "      <td>93553.2</td>\n",
       "      <td>25869.0</td>\n",
       "      <td>1374.2</td>\n",
       "      <td>2325.2</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>3366</td>\n",
       "      <td>5022.9</td>\n",
       "      <td>9982.7</td>\n",
       "      <td>6595.5</td>\n",
       "      <td>105510.8</td>\n",
       "      <td>38319.9</td>\n",
       "      <td>1169.8</td>\n",
       "      <td>1489.1</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>3367</td>\n",
       "      <td>4348.7</td>\n",
       "      <td>11044.1</td>\n",
       "      <td>6933.7</td>\n",
       "      <td>105346.1</td>\n",
       "      <td>31321.5</td>\n",
       "      <td>1101.7</td>\n",
       "      <td>1875.8</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3116</td>\n",
       "      <td>4310.3</td>\n",
       "      <td>9121.3</td>\n",
       "      <td>6645.2</td>\n",
       "      <td>101564.1</td>\n",
       "      <td>28589.7</td>\n",
       "      <td>1863.4</td>\n",
       "      <td>2550.6</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>3587</td>\n",
       "      <td>4172.0</td>\n",
       "      <td>10429.8</td>\n",
       "      <td>8795.1</td>\n",
       "      <td>123481.9</td>\n",
       "      <td>28049.4</td>\n",
       "      <td>1282.8</td>\n",
       "      <td>2278.8</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3829</td>\n",
       "      <td>4655.8</td>\n",
       "      <td>8916.2</td>\n",
       "      <td>6840.7</td>\n",
       "      <td>102689.1</td>\n",
       "      <td>31238.7</td>\n",
       "      <td>1666.8</td>\n",
       "      <td>1258.1</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subjectId  Pallidum  Putamen  Caudate  Cerebellum-Cortex  \\\n",
       "0         3572    3234.8   9403.7   6425.5           101202.1   \n",
       "1         3756    4021.1  11431.6   8336.5           112507.9   \n",
       "2         3768    4240.4   9828.9   7275.3           108180.9   \n",
       "3         3369    3871.7  11068.1   7607.9            98919.4   \n",
       "4         4004    3584.6   9379.7   5883.9            93553.2   \n",
       "..         ...       ...      ...      ...                ...   \n",
       "210       3366    5022.9   9982.7   6595.5           105510.8   \n",
       "211       3367    4348.7  11044.1   6933.7           105346.1   \n",
       "212       3116    4310.3   9121.3   6645.2           101564.1   \n",
       "213       3587    4172.0  10429.8   8795.1           123481.9   \n",
       "214       3829    4655.8   8916.2   6840.7           102689.1   \n",
       "\n",
       "     Cerebellum-White-Matter  3rd-Ventricle  4th-Ventricle class  \n",
       "0                    25991.9          809.7         1595.2    NC  \n",
       "1                    27906.7         1677.0         3021.0    NC  \n",
       "2                    31634.3         2087.1         2487.0    NC  \n",
       "3                    27742.0          918.2         1360.3    NC  \n",
       "4                    25869.0         1374.2         2325.2    NC  \n",
       "..                       ...            ...            ...   ...  \n",
       "210                  38319.9         1169.8         1489.1    PD  \n",
       "211                  31321.5         1101.7         1875.8    PD  \n",
       "212                  28589.7         1863.4         2550.6    PD  \n",
       "213                  28049.4         1282.8         2278.8    PD  \n",
       "214                  31238.7         1666.8         1258.1    PD  \n",
       "\n",
       "[215 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROI = [\n",
    "      \"subjectId\", \"class\",\n",
    "      \"Left-Putamen\", \"Right-Putamen\", \n",
    "      \"Right-Caudate\", \"Left-Caudate\", \n",
    "      \"Right-Thalamus-Proper\", \"Left-Thalamus-Proper\", \n",
    "      \"Left-Pallidum\", \"Right-Pallidum\", \n",
    "      \"Left-Cerebellum-White-Matter\", \"Right-Cerebellum-White-Matter\", \n",
    "      \"Left-Cerebellum-Cortex\", \"Right-Cerebellum-Cortex\",\n",
    "      \"3rd-Ventricle\", \n",
    "      \"4th-Ventricle\"\n",
    "]\n",
    "df = get_data(\"volumes.csv\", ROI, \"combine\")\n",
    "# df = get_data(\"volumes.csv\", ROI, \"combine\", getDf=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize\n",
    "\n",
    "In this section, normalization of the data using \"Normalization 1\" and \"Normaliztion 2\" techniques are implemented. \n",
    "\n",
    "Normalization 1:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}{\\sigma \\;of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}$$\n",
    "\n",
    "Normalization 2:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}{\\sigma \\;of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize1(df, mean, std):\n",
    "    if mean is None and std is None:\n",
    "        mean = df.mean(axis=0)\n",
    "        std = df.std(axis=0)\n",
    "        normalizedDf = (df - mean)/std\n",
    "        return normalizedDf.values, mean, std\n",
    "\n",
    "    normalizedDf = (df - mean)/std\n",
    "    return normalizedDf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678, -0.70710678, -0.70710678],\n",
       "       [ 0.70710678,  0.70710678,  0.70710678]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing normalization1\n",
    "trainDf = pd.DataFrame(np.array([[1, 2, 3], [3, 4, 7]]),columns=['a', 'b', 'c'])\n",
    "testDf = pd.DataFrame(np.array([[2, 6, 4], [3, 7, 9]]),columns=['a', 'b', 'c'])\n",
    "normTrainDf, trainMean, trainStd = normalize1(trainDf, None, None)\n",
    "normTestDf = normalize1(testDf, trainMean, trainStd)\n",
    "normTrainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize2(df):\n",
    "    df_no_id = df.drop(columns=[\"subjectId\", \"class\"])\n",
    "    metadata_df = utils.parse_metadata()\n",
    "    merged_df = pd.merge(df, metadata_df, on=[\"subjectId\"], how=\"left\")\n",
    "   \n",
    "    stats = {}\n",
    "    for scanner in merged_df[\"scannerType\"].dropna().unique():\n",
    "        mean, std = utils.get_mean_and_stats(merged_df.drop(columns=\"subjectId\"), scanner, df_no_id.shape[1])\n",
    "        stats[scanner] = {\n",
    "            \"mean\": mean.to_dict(),\n",
    "            \"std\": std.to_dict()\n",
    "        }\n",
    "\n",
    "    for index in merged_df.index:\n",
    "        rowInfo = merged_df.iloc[index]\n",
    "        scanner = rowInfo[\"scannerType\"]\n",
    "        mean = list(stats[scanner][\"mean\"].values())\n",
    "        std = list(stats[scanner][\"std\"].values())\n",
    "        df_no_id.iloc[index] = (df_no_id.iloc[index]-mean)/std\n",
    "        \n",
    "    return df_no_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pallidum</th>\n",
       "      <th>Putamen</th>\n",
       "      <th>Caudate</th>\n",
       "      <th>Cerebellum-Cortex</th>\n",
       "      <th>Cerebellum-White-Matter</th>\n",
       "      <th>3rd-Ventricle</th>\n",
       "      <th>4th-Ventricle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.254627</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>-0.489725</td>\n",
       "      <td>-0.341841</td>\n",
       "      <td>-0.731373</td>\n",
       "      <td>-1.033358</td>\n",
       "      <td>-0.373735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.301883</td>\n",
       "      <td>2.070251</td>\n",
       "      <td>1.624695</td>\n",
       "      <td>0.607634</td>\n",
       "      <td>-0.196809</td>\n",
       "      <td>0.362490</td>\n",
       "      <td>1.738754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.735996</td>\n",
       "      <td>0.456097</td>\n",
       "      <td>0.450533</td>\n",
       "      <td>0.244247</td>\n",
       "      <td>0.843845</td>\n",
       "      <td>1.022511</td>\n",
       "      <td>0.947571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006140</td>\n",
       "      <td>1.704153</td>\n",
       "      <td>0.818538</td>\n",
       "      <td>-0.533545</td>\n",
       "      <td>-0.242789</td>\n",
       "      <td>-0.858736</td>\n",
       "      <td>-0.721767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.562185</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>-1.088977</td>\n",
       "      <td>-0.984206</td>\n",
       "      <td>-0.765684</td>\n",
       "      <td>-0.124842</td>\n",
       "      <td>0.707845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2.284984</td>\n",
       "      <td>0.610996</td>\n",
       "      <td>-0.301629</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>2.710298</td>\n",
       "      <td>-0.453807</td>\n",
       "      <td>-0.530935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.950380</td>\n",
       "      <td>1.679982</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.756519</td>\n",
       "      <td>-0.563408</td>\n",
       "      <td>0.042006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.874365</td>\n",
       "      <td>-0.256560</td>\n",
       "      <td>-0.246639</td>\n",
       "      <td>-0.311440</td>\n",
       "      <td>-0.006132</td>\n",
       "      <td>0.662485</td>\n",
       "      <td>1.041801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.600595</td>\n",
       "      <td>1.061291</td>\n",
       "      <td>2.132112</td>\n",
       "      <td>1.529245</td>\n",
       "      <td>-0.156970</td>\n",
       "      <td>-0.271943</td>\n",
       "      <td>0.639098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1.558296</td>\n",
       "      <td>-0.463126</td>\n",
       "      <td>-0.030329</td>\n",
       "      <td>-0.216961</td>\n",
       "      <td>0.733403</td>\n",
       "      <td>0.346073</td>\n",
       "      <td>-0.873188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pallidum   Putamen   Caudate  Cerebellum-Cortex  Cerebellum-White-Matter  \\\n",
       "0   -1.254627  0.027858 -0.489725          -0.341841                -0.731373   \n",
       "1    0.301883  2.070251  1.624695           0.607634                -0.196809   \n",
       "2    0.735996  0.456097  0.450533           0.244247                 0.843845   \n",
       "3    0.006140  1.704153  0.818538          -0.533545                -0.242789   \n",
       "4   -0.562185  0.003687 -1.088977          -0.984206                -0.765684   \n",
       "..        ...       ...       ...                ...                      ...   \n",
       "210  2.284984  0.610996 -0.301629           0.020009                 2.710298   \n",
       "211  0.950380  1.679982  0.072571           0.006177                 0.756519   \n",
       "212  0.874365 -0.256560 -0.246639          -0.311440                -0.006132   \n",
       "213  0.600595  1.061291  2.132112           1.529245                -0.156970   \n",
       "214  1.558296 -0.463126 -0.030329          -0.216961                 0.733403   \n",
       "\n",
       "     3rd-Ventricle  4th-Ventricle  \n",
       "0        -1.033358      -0.373735  \n",
       "1         0.362490       1.738754  \n",
       "2         1.022511       0.947571  \n",
       "3        -0.858736      -0.721767  \n",
       "4        -0.124842       0.707845  \n",
       "..             ...            ...  \n",
       "210      -0.453807      -0.530935  \n",
       "211      -0.563408       0.042006  \n",
       "212       0.662485       1.041801  \n",
       "213      -0.271943       0.639098  \n",
       "214       0.346073      -0.873188  \n",
       "\n",
       "[215 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing normalization2\n",
    "df_norm2 = get_data(\"volumes.csv\", ROI, \"combine\")\n",
    "normalize2Df = normalize2(df_norm2)\n",
    "normalize2Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "In this section, we define four models being logisitc regression, SVM with linear and radial kernel and a random forest. As per the paper:\n",
    "\n",
    "_Using the scikit-learn package, four supervised\n",
    "machine learning algorithms were used: logistic regression, support vector machine (SVM) with a linear kernel, SVM with a radial basis function kernel, and\n",
    "random forest_ (Chougar et al.)\n",
    "\n",
    "Additionally, we will implement a stratified cross validation loop for hyperparameter tuning. As per the paper:\n",
    "\n",
    "_The cross-validation procedure on the training cohort included two nested loops: an outer loop with repeated stratified random splits with 50 repetitions evaluating the classification performances and an inner loop with 5 fold cross-validation used to optimize the hyperparameters of the algorithms_ (Chougar et al.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Utils\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Parallel job\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our cross validation loop produces 250 folds per model, it is bound to take a long time to run. Therefore, a refined version of the code above is re-written in parallel. \n",
    "\n",
    "It is recommended that you run the following code from your terminal:\n",
    "```\n",
    "conda activate research # Check README to get corect CONDA environemnt\n",
    "cd ml/\n",
    "python run.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(clf, train_index, test_index, X, y, normalize, columns, modelType, reportKey, iteration):\n",
    "    print(f\"=================Iteration #{iteration}=================\")\n",
    "    performanceDict = {}\n",
    "        \n",
    "    # Get fold data train/test sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    print(f'Shape of train set: {X_train.shape}')\n",
    "    print(f'Shape of test set: {X_test.shape}')\n",
    "    \n",
    "    # Normalize model data\n",
    "    print(\"Normalizing data...\")\n",
    "    if normalize.__name__ == \"normalize1\":\n",
    "        trainDf = pd.DataFrame(X_train, columns=columns).drop(columns=[\"subjectId\", \"class\"])\n",
    "        testDf = pd.DataFrame(X_test, columns=columns).drop(columns=[\"subjectId\", \"class\"])\n",
    "        X_train_normalized, mean_train, std_train = normalize(trainDf, None, None)\n",
    "        X_test_normalized = normalize(testDf, mean_train, std_train)\n",
    "\n",
    "    elif normalize.__name__ == \"normalize2\":\n",
    "        trainDf = pd.DataFrame(X_train, columns=columns)\n",
    "        testDf = pd.DataFrame(X_test, columns=columns)\n",
    "        X_train_normalized = normalize2(trainDf)\n",
    "        X_test_normalized = normalize2(testDf)\n",
    "        \n",
    "    print(\"Done normalizing data\")\n",
    "        \n",
    "    print(f\"Fitting {modelType} model #{iteration}...\")\n",
    "    model = clf.fit(X_train_normalized, y_train)\n",
    "    print(\"Done fitting model\")\n",
    "    \n",
    "    print(f\"Computing results metrics for {modelType} model #{iteration}...\")\n",
    "    performanceDict = utils.performance_report(model, modelType, reportKey, iteration, X_train_normalized, X_test_normalized, y_train, y_test)\n",
    "    print(\"Done computing results metrics\\n\")\n",
    "\n",
    "    return performanceDict\n",
    "\n",
    "def parallel_model(df, modelType, reportKey, normalize, paramGrid, dataFile, ROI, heuristic=None):\n",
    "    print(f\"\\n======================Running {modelType} with the following parameters======================\\nNormalization: {normalize.__name__}\\nParam Grid: {paramGrid}\\nData: {dataFile}\\nROI: {ROI}\")\n",
    "\n",
    "    performance = []\n",
    "    if not os.path.isdir(modelType):\n",
    "        os.mkdir(modelType)\n",
    "\n",
    "    X = df.values\n",
    "    y = utils.convert_Y(X[:, -1])\n",
    "    columns = df.columns\n",
    "    \n",
    "    # Setup CV\n",
    "    cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=3, random_state=42)\n",
    "\n",
    "    # Define model type\n",
    "    if modelType == \"SVM\":\n",
    "        clf = GridSearchCV(SVC(random_state=0), paramGrid)\n",
    "    elif modelType == \"RF\":\n",
    "        clf = GridSearchCV(RandomForestClassifier(random_state=0, n_jobs = -1), paramGrid)\n",
    "    elif modelType == \"LR\":\n",
    "        clf = GridSearchCV(LogisticRegression(random_state=0), paramGrid)\n",
    "    \n",
    "    output = Parallel(n_jobs=-1)(delayed(train)(clf, train_index, test_index, X, y, normalize, columns, modelType, reportKey, iteration) for iteration, (train_index, test_index) in enumerate(cv.split(X, y)))\n",
    "\n",
    "    performance.append(output)\n",
    "\n",
    "    with open(f\"{modelType}/{reportKey}_report.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(performance, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameter grid per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_LINEAR_PARAMS = {\n",
    "    'C': [1.0, 10.0, 100.0, 1000.0],\n",
    "    'gamma': [0.01, 0.10, 1.00, 10.00],\n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "SVM_RBF_PARAMS = {\n",
    "    'C': [1.0, 10.0, 100.0, 1000.0],\n",
    "    'gamma': [0.01, 0.10, 1.00, 10.00],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "LR_PARAMS = {\n",
    "    'penalty': [\"l1\", \"l2\", \"elasticnet\"],\n",
    "    'C': [1.0, 10.0, 100.0, 1000.0]\n",
    "}\n",
    "\n",
    "RF_PARAMS = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 4, 5, 10, 13],\n",
    "    'min_samples_leaf': [1, 2, 5, 8, 13]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing models\n",
    "As suggested earlier, it is preferable to run the models in a separate shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(\"volumes.csv\", ROI, \"combine\")\n",
    "\n",
    "# SVM - Linear\n",
    "# parallel_model(df, \"SVM\", \"linear_svm_norm1\", normalize1, SVM_LINEAR_PARAMS, \"volumes.csv\", ROI, heuristic=\"combine\")\n",
    "# parallel_model(df, \"SVM\", \"linear_svm_norm1\", normalize2, SVM_LINEAR_PARAMS, \"volumes.csv\", ROI, heuristic=\"combine\")\n",
    "\n",
    "# SVM - RBF\n",
    "# parallel_model(X, y, \"SVM\", \"rbf_svm_norm1\", 0.7, normalize1, SVM_RBF_PARAMS, \"volumes.csv\", ROI, heuristic=\"combine\")\n",
    "# parallel_model(X, y, \"SVM\", \"rbf_svm_norm1\", 0.7, normalize2, SVM_RBF_PARAMS, \"volumes.csv\", ROI, heuristic=\"combine\")\n",
    "\n",
    "# Logistic Regression\n",
    "# parallel_model(X, y, \"LR\", \"lr_norm1\", 0.7, normalize1, LR_PARAMS, \"volumes.csv\", ROI, heuristic=\"combine\")\n",
    "# parallel_model(X, y, \"LR\", \"lr_norm2\", 0.7, normalize2, LR_PARAMS, \"volumes.csv\", ROI, heuristic=\"combine\")\n",
    "\n",
    "# Random Forest\n",
    "# parallel_model(X, y, \"RF\", \"rf_norm1\", 0.7, normalize1, RF_PARAMS, \"volumes.csv\", ROI, heuristic=\"combine\")\n",
    "# parallel_model(X, y, \"RF\", \"rf_norm2\",0.7, normalize2, RF_PARAMS, \"volumes.csv\", ROI, heuristic=\"combine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results can be found in the [analysis notebook](analysis.ipynb) for a detailed breakdown of the models and comparasions to the papers' results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
