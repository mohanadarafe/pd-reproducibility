{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb3f3e9",
   "metadata": {},
   "source": [
    "# Machine Learning pipeline\n",
    "\n",
    "In this notebook, we go through the machine learning pipeline to reproduce Lydia Chougar's paper. The following sections will be covered:\n",
    "\n",
    "1 - Convert CSV to DataFrame\n",
    "\n",
    "2 - Normalize\n",
    "\n",
    "3 - Train and predict models\n",
    "\n",
    "4 - Cross Validation\n",
    "\n",
    "5 - Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc488c91",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42237f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, utils, sys\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7ea21",
   "metadata": {},
   "source": [
    "# Convert CSV to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b341a",
   "metadata": {},
   "source": [
    "Converts data from CSV to DataFrame and applies any function. \n",
    "- \"combine\": sums all Left and Right regions into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac891096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(csvFileName: str, ROI: [], heuristic = None, getDf = False):\n",
    "    '''\n",
    "    The following function will sanitize data and build a numpy array with X ROI's volumes and y being the class [NC, PD]\n",
    "    @csvFileName: input volumes csv\n",
    "    @ROI: regions of interests desired\n",
    "    @heuristic: function key\n",
    "    '''\n",
    "    df = pd.read_csv(csvFileName)\n",
    "    df = utils.remove_unwanted_columns(df, ROI)\n",
    "    \n",
    "    if heuristic == \"combine\":\n",
    "        df = utils.combine_left_right_vol(df)\n",
    "        \n",
    "    if (getDf):\n",
    "        cols = list(df.columns.values)\n",
    "        cols.pop(cols.index(\"subjectId\"))\n",
    "        df = df[[\"subjectId\"]+cols]\n",
    "        return df\n",
    "    else:\n",
    "        df = df.drop(\"subjectId\", 1)\n",
    "        \n",
    "    arr = df.values\n",
    "    X = arr[:, :-1]\n",
    "    y = utils.convert_Y(arr[:, -1])\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b76c0a",
   "metadata": {},
   "source": [
    "Test *get_data()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dba8c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/anaconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectId</th>\n",
       "      <th>Pallidum</th>\n",
       "      <th>Putamen</th>\n",
       "      <th>Caudate</th>\n",
       "      <th>Cerebellum-Cortex</th>\n",
       "      <th>Cerebellum-White-Matter</th>\n",
       "      <th>3rd-Ventricle</th>\n",
       "      <th>4th-Ventricle</th>\n",
       "      <th>lhCortexVol</th>\n",
       "      <th>rhCortexVol</th>\n",
       "      <th>CortexVol</th>\n",
       "      <th>CerebralWhiteMatterVol</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3572</td>\n",
       "      <td>3234.8</td>\n",
       "      <td>9403.7</td>\n",
       "      <td>6425.5</td>\n",
       "      <td>101202.1</td>\n",
       "      <td>25991.9</td>\n",
       "      <td>809.7</td>\n",
       "      <td>1595.2</td>\n",
       "      <td>214211.281877</td>\n",
       "      <td>214614.080385</td>\n",
       "      <td>428825.362262</td>\n",
       "      <td>398502.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3756</td>\n",
       "      <td>4021.1</td>\n",
       "      <td>11431.6</td>\n",
       "      <td>8336.5</td>\n",
       "      <td>112507.9</td>\n",
       "      <td>27906.7</td>\n",
       "      <td>1677.0</td>\n",
       "      <td>3021.0</td>\n",
       "      <td>241712.658555</td>\n",
       "      <td>250985.173323</td>\n",
       "      <td>492697.831879</td>\n",
       "      <td>475569.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3768</td>\n",
       "      <td>4240.4</td>\n",
       "      <td>9828.9</td>\n",
       "      <td>7275.3</td>\n",
       "      <td>108180.9</td>\n",
       "      <td>31634.3</td>\n",
       "      <td>2087.1</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>240319.225000</td>\n",
       "      <td>236183.634262</td>\n",
       "      <td>476502.859262</td>\n",
       "      <td>526061.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3369</td>\n",
       "      <td>3871.7</td>\n",
       "      <td>11068.1</td>\n",
       "      <td>7607.9</td>\n",
       "      <td>98919.4</td>\n",
       "      <td>27742.0</td>\n",
       "      <td>918.2</td>\n",
       "      <td>1360.3</td>\n",
       "      <td>227101.242448</td>\n",
       "      <td>229470.755367</td>\n",
       "      <td>456571.997815</td>\n",
       "      <td>420273.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4004</td>\n",
       "      <td>3584.6</td>\n",
       "      <td>9379.7</td>\n",
       "      <td>5883.9</td>\n",
       "      <td>93553.2</td>\n",
       "      <td>25869.0</td>\n",
       "      <td>1374.2</td>\n",
       "      <td>2325.2</td>\n",
       "      <td>215114.677435</td>\n",
       "      <td>213485.100332</td>\n",
       "      <td>428599.777767</td>\n",
       "      <td>388901.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>3366</td>\n",
       "      <td>5022.9</td>\n",
       "      <td>9982.7</td>\n",
       "      <td>6595.5</td>\n",
       "      <td>105510.8</td>\n",
       "      <td>38319.9</td>\n",
       "      <td>1169.8</td>\n",
       "      <td>1489.1</td>\n",
       "      <td>221069.501788</td>\n",
       "      <td>222936.985582</td>\n",
       "      <td>444006.487370</td>\n",
       "      <td>503456.0</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>3367</td>\n",
       "      <td>4348.7</td>\n",
       "      <td>11044.1</td>\n",
       "      <td>6933.7</td>\n",
       "      <td>105346.1</td>\n",
       "      <td>31321.5</td>\n",
       "      <td>1101.7</td>\n",
       "      <td>1875.8</td>\n",
       "      <td>222235.310341</td>\n",
       "      <td>227057.206724</td>\n",
       "      <td>449292.517066</td>\n",
       "      <td>472333.0</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3116</td>\n",
       "      <td>4310.3</td>\n",
       "      <td>9121.3</td>\n",
       "      <td>6645.2</td>\n",
       "      <td>101564.1</td>\n",
       "      <td>28589.7</td>\n",
       "      <td>1863.4</td>\n",
       "      <td>2550.6</td>\n",
       "      <td>198129.877854</td>\n",
       "      <td>201670.182642</td>\n",
       "      <td>399800.060496</td>\n",
       "      <td>404765.0</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>3587</td>\n",
       "      <td>4172.0</td>\n",
       "      <td>10429.8</td>\n",
       "      <td>8795.1</td>\n",
       "      <td>123481.9</td>\n",
       "      <td>28049.4</td>\n",
       "      <td>1282.8</td>\n",
       "      <td>2278.8</td>\n",
       "      <td>282485.457627</td>\n",
       "      <td>284700.760325</td>\n",
       "      <td>567186.217952</td>\n",
       "      <td>501236.0</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3829</td>\n",
       "      <td>4655.8</td>\n",
       "      <td>8916.2</td>\n",
       "      <td>6840.7</td>\n",
       "      <td>102689.1</td>\n",
       "      <td>31238.7</td>\n",
       "      <td>1666.8</td>\n",
       "      <td>1258.1</td>\n",
       "      <td>216814.479354</td>\n",
       "      <td>217215.692236</td>\n",
       "      <td>434030.171590</td>\n",
       "      <td>456889.0</td>\n",
       "      <td>PD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subjectId  Pallidum  Putamen  Caudate  Cerebellum-Cortex  \\\n",
       "0         3572    3234.8   9403.7   6425.5           101202.1   \n",
       "1         3756    4021.1  11431.6   8336.5           112507.9   \n",
       "2         3768    4240.4   9828.9   7275.3           108180.9   \n",
       "3         3369    3871.7  11068.1   7607.9            98919.4   \n",
       "4         4004    3584.6   9379.7   5883.9            93553.2   \n",
       "..         ...       ...      ...      ...                ...   \n",
       "210       3366    5022.9   9982.7   6595.5           105510.8   \n",
       "211       3367    4348.7  11044.1   6933.7           105346.1   \n",
       "212       3116    4310.3   9121.3   6645.2           101564.1   \n",
       "213       3587    4172.0  10429.8   8795.1           123481.9   \n",
       "214       3829    4655.8   8916.2   6840.7           102689.1   \n",
       "\n",
       "     Cerebellum-White-Matter  3rd-Ventricle  4th-Ventricle    lhCortexVol  \\\n",
       "0                    25991.9          809.7         1595.2  214211.281877   \n",
       "1                    27906.7         1677.0         3021.0  241712.658555   \n",
       "2                    31634.3         2087.1         2487.0  240319.225000   \n",
       "3                    27742.0          918.2         1360.3  227101.242448   \n",
       "4                    25869.0         1374.2         2325.2  215114.677435   \n",
       "..                       ...            ...            ...            ...   \n",
       "210                  38319.9         1169.8         1489.1  221069.501788   \n",
       "211                  31321.5         1101.7         1875.8  222235.310341   \n",
       "212                  28589.7         1863.4         2550.6  198129.877854   \n",
       "213                  28049.4         1282.8         2278.8  282485.457627   \n",
       "214                  31238.7         1666.8         1258.1  216814.479354   \n",
       "\n",
       "       rhCortexVol      CortexVol  CerebralWhiteMatterVol class  \n",
       "0    214614.080385  428825.362262                398502.0    NC  \n",
       "1    250985.173323  492697.831879                475569.0    NC  \n",
       "2    236183.634262  476502.859262                526061.0    NC  \n",
       "3    229470.755367  456571.997815                420273.0    NC  \n",
       "4    213485.100332  428599.777767                388901.0    NC  \n",
       "..             ...            ...                     ...   ...  \n",
       "210  222936.985582  444006.487370                503456.0    PD  \n",
       "211  227057.206724  449292.517066                472333.0    PD  \n",
       "212  201670.182642  399800.060496                404765.0    PD  \n",
       "213  284700.760325  567186.217952                501236.0    PD  \n",
       "214  217215.692236  434030.171590                456889.0    PD  \n",
       "\n",
       "[215 rows x 13 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROI = [\n",
    "      \"subjectId\", \"class\",\n",
    "      \"Left-Putamen\", \"Right-Putamen\", \n",
    "      \"Right-Caudate\", \"Left-Caudate\", \n",
    "      \"Right-Thalamus-Proper\", \"Left-Thalamus-Proper\", \n",
    "      \"Left-Pallidum\", \"Right-Pallidum\", \n",
    "      \"Left-Cerebellum-Cortex\", \"Right-Cerebellum-Cortex\", \"lhCortexVol\", \"rhCortexVol\", \"CortexVol\",\n",
    "      \"Left-Cerebellum-White-Matter\", \"Right-Cerebellum-White-Matter\",\n",
    "      \"CerebralWhiteMatterVol\", \n",
    "      \"3rd-Ventricle\", \"4th-Ventricle\"\n",
    "   ]\n",
    "X, y = get_data(\"volumes.csv\", ROI, \"combine\")\n",
    "df = get_data(\"volumes.csv\", ROI, \"combine\", getDf=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909a3d1",
   "metadata": {},
   "source": [
    "# 2. [Normalize](#normal)\n",
    "\n",
    "In this section, normalization of the data using \"Normalization 1\" and \"Normaliztion 2\" techniques are implemented. \n",
    "\n",
    "Normalization 1:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}{\\sigma \\;of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}$$\n",
    "\n",
    "Normalization 2:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}{\\sigma \\;of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e12cafd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize1(data, mean, std):\n",
    "    df = pd.DataFrame(data=data)\n",
    "\n",
    "    if mean is None and std is None:\n",
    "        mean = df.mean(axis=0)\n",
    "        std = df.std(axis=0)\n",
    "        normalizedDf = (df - mean)/std\n",
    "        return normalizedDf.values, mean, std\n",
    "\n",
    "    normalizedDf = (df - mean)/std\n",
    "    return normalizedDf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "16a4221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    2.0\n",
      "b    3.0\n",
      "c    5.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678, -0.70710678, -0.70710678],\n",
       "       [ 0.70710678,  0.70710678,  0.70710678]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing normalization1\n",
    "trainDf = pd.DataFrame(np.array([[1, 2, 3], [3, 4, 7]]),columns=['a', 'b', 'c'])\n",
    "testDf = pd.DataFrame(np.array([[2, 6, 4], [3, 7, 9]]),columns=['a', 'b', 'c'])\n",
    "normTrainDf, trainMean, trainStd = normalize1(trainDf, None, None)\n",
    "print(trainMean)\n",
    "normTestDf = normalize1(testDf, trainMean, trainStd)\n",
    "normTrainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c572ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize2(df):\n",
    "    df_no_id = df.drop([\"subjectId\", \"class\"], 1)\n",
    "    metadata_df = utils.parse_metadata()\n",
    "    merged_df = pd.merge(df, metadata_df, on=[\"subjectId\"])\n",
    "    \n",
    "    stats = {}\n",
    "    for scanner in merged_df[\"scannerType\"].unique():\n",
    "        mean, std = utils.get_mean_and_stats(merged_df.drop(\"subjectId\",1), scanner)\n",
    "        stats[scanner] = {\n",
    "            \"mean\": mean.to_dict(),\n",
    "            \"std\": std.to_dict()\n",
    "        }\n",
    "        \n",
    "    for index in merged_df.index:\n",
    "        rowInfo = merged_df.iloc[index]\n",
    "        scanner = rowInfo[\"scannerType\"]\n",
    "        mean = list(stats[scanner][\"mean\"].values())\n",
    "        std = list(stats[scanner][\"std\"].values())\n",
    "        df_no_id.iloc[index] = (df_no_id.iloc[index]-mean)/std\n",
    "        \n",
    "    return df_no_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ba159776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/anaconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n",
      "/home/mohanad/anaconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678, -0.70710678, -0.70710678, -0.70710678, -0.70710678,\n",
       "        -0.70710678, -0.70710678, -0.70710678, -0.70710678, -0.70710678,\n",
       "        -0.70710678],\n",
       "       [ 0.70710678,  0.70710678,  0.70710678,  0.70710678,  0.70710678,\n",
       "         0.70710678,  0.70710678,  0.70710678,  0.70710678,  0.70710678,\n",
       "         0.70710678],\n",
       "       [ 1.82235096,  2.68279471,  0.65286694,  1.58555251,  6.58397649,\n",
       "         0.69631596,  2.55149474, 11.59372081,  2.76593576,  4.94406413,\n",
       "         2.81328748],\n",
       "       [ 0.70710678,  0.70710678,  0.70710678, -0.70710678,  0.70710678,\n",
       "        -0.70710678, -0.70710678, -0.70710678, -0.70710678, -0.70710678,\n",
       "         0.70710678],\n",
       "       [-0.70710678, -0.70710678, -0.70710678,  0.70710678, -0.70710678,\n",
       "         0.70710678,  0.70710678,  0.70710678,  0.70710678,  0.70710678,\n",
       "        -0.70710678]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm2 = get_data(\"test.csv\", ROI, \"combine\", getDf=True)\n",
    "normalize2Df = normalize2(df_norm2)\n",
    "normalize2Df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52157a2b",
   "metadata": {},
   "source": [
    "# 3. [Train and predict models](#predict)\n",
    "\n",
    "In this section, we define four models being logisitc regression, SVM with linear and radial kernel and a random forest. As per the paper:\n",
    "\n",
    "_Using the scikit-learn package, four supervised\n",
    "machine learning algorithms were used: logistic regression, support vector machine (SVM) with a linear kernel, SVM with a radial basis function kernel, and\n",
    "random forest_ (Chougar et al.)\n",
    "\n",
    "Additionally, we will implement a stratified cross validation loop for hyperparameter tuning. As per the paper:\n",
    "\n",
    "_The cross-validation procedure on the training cohort included two nested loops: an outer loop with repeated stratified random splits with 50 repetitions evaluating the classification performances and an inner loop with 5 fold cross-validation used to optimize the hyperparameters of the algorithms_ (Chougar et al.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f25f2dd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e9bd77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Utils\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a2481",
   "metadata": {},
   "source": [
    "## Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d6b982c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, training_split):\n",
    "    '''\n",
    "    The following function splits the training and testing data sets\n",
    "    according to a split [0 - 1] passed.\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = training_split, random_state = 42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_model_score(model, X_train, y_train, X_test, y_test):\n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print(f'training score: {round(train_acc, 3)}')\n",
    "    print(f'testing score: {round(test_acc, 3)}')\n",
    "    return train_acc, test_acc\n",
    "\n",
    "def model(X, y, modelType, dataSplit, normalize, paramGrid, dataFile, ROI, heuristic=None):\n",
    "    # Define training, validation and test sets\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, dataSplit)\n",
    "    \n",
    "    # Setup CV\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=50)\n",
    "    \n",
    "    # Define model type\n",
    "    if modelType == \"SVM\":\n",
    "        clf = GridSearchCV(SVC(random_state=0), paramGrid, cv=cv)\n",
    "    elif modelType == \"RF\":\n",
    "        clf = GridSearchCV(RandomForestClassifier(random_state=0), paramGrid, cv=cv)\n",
    "    elif modelType == \"LR\":\n",
    "        clf = GridSearchCV(LogisticRegression(random_state=0), paramGrid, cv=cv)\n",
    "        \n",
    "    # Normalize model data\n",
    "    if normalize.__name__ == \"normalize1\":\n",
    "        X_train_normalized, mean_train, std_train = normalize(X_train, None, None)\n",
    "        X_test_normalized = normalize(X_test, mean_train, std_train)\n",
    "        \n",
    "    elif normalize.__name__ == \"normalize2\":\n",
    "        df = get_data(dataFile, ROI, heuristic, getDf=True)\n",
    "        X_train, X_test, y_train, y_test = split_data(df, y, dataSplit)\n",
    "        X_train_normalized = normalize2(X_train)\n",
    "        X_test_normalized = normalize2(X_test)\n",
    "        \n",
    "    # Fit and predict\n",
    "    model = clf.fit(X_train_normalized, y_train)\n",
    "    train_acc = cross_val_score(model, X_train_normalized, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    test_acc = cross_val_score(model, X_test_normalized, y_test, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print(f'training score: {round(train_acc, 3)}')\n",
    "    print(f'testing score: {round(test_acc, 3)}')\n",
    "#     train_acc, test_acc = get_model_score(model, X_train_normalized, y_train, X_test_normalized, y_test)\n",
    "    print(f'Best model params: {model.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b64ac672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohanad/Desktop/research/pd-reproducibility/ml/utils.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop(column, 1)\n",
      "/home/mohanad/anaconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "/home/mohanad/anaconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n",
      "/home/mohanad/anaconda3/envs/research/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n",
      "/home/mohanad/Desktop/research/pd-reproducibility/ml/utils.py:48: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean = queryDf.mean()\n",
      "/home/mohanad/Desktop/research/pd-reproducibility/ml/utils.py:49: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  std = queryDf.std()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_486196/1341999792.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"volumes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"combine\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SVM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"volumes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"combine\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_486196/1887166793.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X, y, modelType, dataSplit, normalize, paramGrid, dataFile, ROI, heuristic)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Fit and predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'training score: {round(train_acc, 3)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [1.0, 10.0, 100.0, 1000.0],\n",
    "    'gamma': [0.01, 0.10, 1.00, 10.00]\n",
    "}\n",
    "X, y = get_data(\"volumes.csv\", ROI, \"combine\")\n",
    "model(X, y, \"SVM\", 0.7, normalize2, param_grid, \"volumes.csv\", ROI, heuristic=\"combine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91094b77",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4225c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [1.0, 10.0, 100.0, 1000.0],\n",
    "    'gamma': [0.01, 0.10, 1.00, 10.00]\n",
    "}\n",
    "for kernelType in [\"linear\", \"rbf\"]:\n",
    "    param_grid[\"kernel\"] = kernelType\n",
    "    model(X, y, \"SVM\", 0.7, normalize1, param_grid, \"test.csv\", ROI, heuristic=\"heurisitc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de088725",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb876216",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': [\"l1\", \"l2\", \"elasticnet\"],\n",
    "    'C': [1.0, 10.0, 100.0, 1000.0]\n",
    "}\n",
    "# model(X, y, \"LR\", 0.7, normalize1, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f48d25",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b70ad5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 4, 5, 10, 13],\n",
    "    'min_samples_leaf': [1, 2, 5, 8, 13]\n",
    "}\n",
    "# model(X, y, \"RF\", 0.7, normalize1, param_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
