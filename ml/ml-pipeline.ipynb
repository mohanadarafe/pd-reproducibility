{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline\n",
    "In this notebook, we will develop the machine learning models by preprocessing and training the data in four models as per Lydia Chougar's pipeline.\n",
    "\n",
    "[1. Convert CSV to DataFrame](#data)\n",
    "\n",
    "[2. Normalize data](#normalize)\n",
    "\n",
    "[3. Define models](#models)\n",
    "\n",
    "[4. Training models](#training)\n",
    "\n",
    "[5. Results](#results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, sys, os, json, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(csvFileName: str, ROI: []):\n",
    "    '''\n",
    "    The following function will sanitize data and build a numpy array with X ROI's volumes and y being the class [NC, PD]\n",
    "    @csvFileName: input volumes csv\n",
    "    @ROI: regions of interests desired\n",
    "    '''\n",
    "    df = pd.read_csv(csvFileName)\n",
    "    df = utils.remove_unwanted_columns(df, ROI)\n",
    "    df = utils.combine_left_right_vol(df)\n",
    "        \n",
    "    cols = list(df.columns.values)\n",
    "    cols.pop(cols.index(\"subjectId\"))\n",
    "    df = df[[\"subjectId\"]+cols]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectId</th>\n",
       "      <th>Pallidum</th>\n",
       "      <th>Putamen</th>\n",
       "      <th>Caudate</th>\n",
       "      <th>Thalamus-Proper</th>\n",
       "      <th>Cerebellum-Cortex</th>\n",
       "      <th>Cerebellum-White-Matter</th>\n",
       "      <th>3rd-Ventricle</th>\n",
       "      <th>SCP</th>\n",
       "      <th>Midbrain</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4037</td>\n",
       "      <td>4261.3</td>\n",
       "      <td>10223.0</td>\n",
       "      <td>7586.8</td>\n",
       "      <td>17351.7</td>\n",
       "      <td>116856.4</td>\n",
       "      <td>38230.0</td>\n",
       "      <td>934.2</td>\n",
       "      <td>307.724746</td>\n",
       "      <td>6989.344230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3168</td>\n",
       "      <td>3776.7</td>\n",
       "      <td>8200.9</td>\n",
       "      <td>5738.2</td>\n",
       "      <td>13200.4</td>\n",
       "      <td>91395.5</td>\n",
       "      <td>31986.1</td>\n",
       "      <td>1089.4</td>\n",
       "      <td>281.394581</td>\n",
       "      <td>5453.716726</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3131</td>\n",
       "      <td>4523.6</td>\n",
       "      <td>9383.2</td>\n",
       "      <td>8577.0</td>\n",
       "      <td>16020.2</td>\n",
       "      <td>118487.3</td>\n",
       "      <td>34742.2</td>\n",
       "      <td>1719.7</td>\n",
       "      <td>348.730585</td>\n",
       "      <td>8004.224865</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4024</td>\n",
       "      <td>3444.1</td>\n",
       "      <td>8405.3</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>12945.9</td>\n",
       "      <td>93723.6</td>\n",
       "      <td>22075.2</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>297.837617</td>\n",
       "      <td>5969.685193</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4001</td>\n",
       "      <td>4174.6</td>\n",
       "      <td>11058.9</td>\n",
       "      <td>7890.2</td>\n",
       "      <td>15731.7</td>\n",
       "      <td>126094.9</td>\n",
       "      <td>29284.0</td>\n",
       "      <td>1650.6</td>\n",
       "      <td>262.838901</td>\n",
       "      <td>7330.256842</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3753</td>\n",
       "      <td>3443.9</td>\n",
       "      <td>9007.8</td>\n",
       "      <td>6511.1</td>\n",
       "      <td>14335.3</td>\n",
       "      <td>103145.8</td>\n",
       "      <td>25126.6</td>\n",
       "      <td>1366.5</td>\n",
       "      <td>241.183927</td>\n",
       "      <td>5918.611366</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3372</td>\n",
       "      <td>4797.0</td>\n",
       "      <td>10114.8</td>\n",
       "      <td>9268.2</td>\n",
       "      <td>15093.5</td>\n",
       "      <td>112521.2</td>\n",
       "      <td>36136.9</td>\n",
       "      <td>3301.4</td>\n",
       "      <td>318.438874</td>\n",
       "      <td>6918.687371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3589</td>\n",
       "      <td>3067.4</td>\n",
       "      <td>7619.4</td>\n",
       "      <td>6386.1</td>\n",
       "      <td>13104.2</td>\n",
       "      <td>92495.3</td>\n",
       "      <td>29665.6</td>\n",
       "      <td>1319.4</td>\n",
       "      <td>283.262188</td>\n",
       "      <td>5467.899590</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3586</td>\n",
       "      <td>3709.8</td>\n",
       "      <td>8082.5</td>\n",
       "      <td>5973.9</td>\n",
       "      <td>13831.9</td>\n",
       "      <td>109396.4</td>\n",
       "      <td>29020.2</td>\n",
       "      <td>1464.9</td>\n",
       "      <td>342.644554</td>\n",
       "      <td>6638.502535</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3321</td>\n",
       "      <td>4385.8</td>\n",
       "      <td>8448.1</td>\n",
       "      <td>5641.0</td>\n",
       "      <td>11139.7</td>\n",
       "      <td>83367.7</td>\n",
       "      <td>25169.8</td>\n",
       "      <td>1547.2</td>\n",
       "      <td>248.712139</td>\n",
       "      <td>5117.555339</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subjectId  Pallidum  Putamen  Caudate  Thalamus-Proper  \\\n",
       "0         4037    4261.3  10223.0   7586.8          17351.7   \n",
       "1         3168    3776.7   8200.9   5738.2          13200.4   \n",
       "2         3131    4523.6   9383.2   8577.0          16020.2   \n",
       "3         4024    3444.1   8405.3   5940.0          12945.9   \n",
       "4         4001    4174.6  11058.9   7890.2          15731.7   \n",
       "..         ...       ...      ...      ...              ...   \n",
       "146       3753    3443.9   9007.8   6511.1          14335.3   \n",
       "147       3372    4797.0  10114.8   9268.2          15093.5   \n",
       "148       3589    3067.4   7619.4   6386.1          13104.2   \n",
       "149       3586    3709.8   8082.5   5973.9          13831.9   \n",
       "150       3321    4385.8   8448.1   5641.0          11139.7   \n",
       "\n",
       "     Cerebellum-Cortex  Cerebellum-White-Matter  3rd-Ventricle         SCP  \\\n",
       "0             116856.4                  38230.0          934.2  307.724746   \n",
       "1              91395.5                  31986.1         1089.4  281.394581   \n",
       "2             118487.3                  34742.2         1719.7  348.730585   \n",
       "3              93723.6                  22075.2         1587.0  297.837617   \n",
       "4             126094.9                  29284.0         1650.6  262.838901   \n",
       "..                 ...                      ...            ...         ...   \n",
       "146           103145.8                  25126.6         1366.5  241.183927   \n",
       "147           112521.2                  36136.9         3301.4  318.438874   \n",
       "148            92495.3                  29665.6         1319.4  283.262188   \n",
       "149           109396.4                  29020.2         1464.9  342.644554   \n",
       "150            83367.7                  25169.8         1547.2  248.712139   \n",
       "\n",
       "        Midbrain  stage  \n",
       "0    6989.344230    1.0  \n",
       "1    5453.716726    2.0  \n",
       "2    8004.224865    2.0  \n",
       "3    5969.685193    2.0  \n",
       "4    7330.256842    2.0  \n",
       "..           ...    ...  \n",
       "146  5918.611366    2.0  \n",
       "147  6918.687371    1.0  \n",
       "148  5467.899590    2.0  \n",
       "149  6638.502535    1.0  \n",
       "150  5117.555339    2.0  \n",
       "\n",
       "[151 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROI = [\n",
    "      \"subjectId\", \"stage\",\n",
    "      \"Left-Putamen\", \"Right-Putamen\", \n",
    "      \"Right-Caudate\", \"Left-Caudate\", \n",
    "      \"Right-Thalamus-Proper\", \"Left-Thalamus-Proper\", \n",
    "      \"Left-Pallidum\", \"Right-Pallidum\", \n",
    "      \"Left-Cerebellum-White-Matter\", \"Right-Cerebellum-White-Matter\", \n",
    "      \"Left-Cerebellum-Cortex\", \"Right-Cerebellum-Cortex\",\n",
    "      \"3rd-Ventricle\", \n",
    "      \"4th-Ventricle\"\n",
    "      \"Pons\",\n",
    "      \"SCP\",\n",
    "      \"Midbrain\"\n",
    "]\n",
    "df = get_data(\"../data/volumes.csv\", ROI)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize\n",
    "\n",
    "In this section, normalization of the data using \"Normalization 1\" and \"Normaliztion 2\" techniques are implemented. \n",
    "\n",
    "Normalization 1:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}{\\sigma \\;of \\;PD \\;and \\;NC \\;in \\;the \\;training \\;cohort}$$\n",
    "\n",
    "Normalization 2:\n",
    "\n",
    "$$\\dfrac{Variable – mean \\; of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}{\\sigma \\;of \\;controls \\;scanned \\;using \\;the \\;same \\;scanner}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize1(df, mean, std):\n",
    "    if mean is None and std is None:\n",
    "        mean = df.mean(axis=0)\n",
    "        std = df.std(axis=0)\n",
    "        normalizedDf = (df - mean)/std\n",
    "        return normalizedDf.values, mean, std\n",
    "\n",
    "    normalizedDf = (df - mean)/std\n",
    "    return normalizedDf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize2(df):\n",
    "    df_no_id = df.drop(columns=[\"subjectId\", \"stage\"])\n",
    "    metadata_df = utils.parse_metadata()\n",
    "    merged_df = pd.merge(df, metadata_df, on=[\"subjectId\"], how=\"left\")\n",
    "   \n",
    "    stats = {}\n",
    "    for scanner in merged_df[\"scannerType\"].dropna().unique():\n",
    "        mean, std = utils.get_mean_and_stats(merged_df.drop(columns=\"subjectId\"), scanner, df_no_id.shape[1])\n",
    "        stats[scanner] = {\n",
    "            \"mean\": mean.to_dict(),\n",
    "            \"std\": std.to_dict()\n",
    "        }\n",
    "\n",
    "    for index in merged_df.index:\n",
    "        rowInfo = merged_df.iloc[index]\n",
    "        scanner = rowInfo[\"scannerType\"]\n",
    "        mean = list(stats[scanner][\"mean\"].values())\n",
    "        std = list(stats[scanner][\"std\"].values())\n",
    "        df_no_id.iloc[index] = (df_no_id.iloc[index]-mean)/std\n",
    "        \n",
    "    return df_no_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "In this section, we define four models being logisitc regression, SVM with linear and radial kernel and a random forest. As per the paper:\n",
    "\n",
    "_Using the scikit-learn package, four supervised\n",
    "machine learning algorithms were used: logistic regression, support vector machine (SVM) with a linear kernel, SVM with a radial basis function kernel, and\n",
    "random forest_ (Chougar et al.)\n",
    "\n",
    "Additionally, we will implement a stratified cross validation loop for hyperparameter tuning. As per the paper:\n",
    "\n",
    "_The cross-validation procedure on the training cohort included two nested loops: an outer loop with repeated stratified random splits with 50 repetitions evaluating the classification performances and an inner loop with 5 fold cross-validation used to optimize the hyperparameters of the algorithms_ (Chougar et al.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Utils\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Parallel job\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel model\n",
    "\n",
    "Since our cross validation loop produces 250 folds per model, it is bound to take a long time to run. Therefore, a refined version of the code above is re-written in parallel. \n",
    "\n",
    "It is recommended that you run the following code from your terminal:\n",
    "```\n",
    "conda activate research # Check README to get corect CONDA environemnt\n",
    "cd ml/\n",
    "python run.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(clf, train_index, test_index, X, y, normalize, columns, modelType, reportKey, iteration):\n",
    "    print(f\"=================Iteration #{iteration}=================\")\n",
    "    performanceDict = {}\n",
    "        \n",
    "    # Get fold data train/test sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    print(f'Shape of train set: {X_train.shape}')\n",
    "    print(f'Shape of test set: {X_test.shape}')\n",
    "    \n",
    "    # Normalize model data\n",
    "    print(\"Normalizing data...\")\n",
    "    if normalize.__name__ == \"normalize1\":\n",
    "        trainDf = pd.DataFrame(X_train, columns=columns).drop(columns=[\"subjectId\", \"class\"])\n",
    "        testDf = pd.DataFrame(X_test, columns=columns).drop(columns=[\"subjectId\", \"class\"])\n",
    "        X_train_normalized, mean_train, std_train = normalize(trainDf, None, None)\n",
    "        X_test_normalized = normalize(testDf, mean_train, std_train)\n",
    "\n",
    "    elif normalize.__name__ == \"normalize2\":\n",
    "        trainDf = pd.DataFrame(X_train, columns=columns)\n",
    "        testDf = pd.DataFrame(X_test, columns=columns)\n",
    "        X_train_normalized = normalize2(trainDf)\n",
    "        X_test_normalized = normalize2(testDf)\n",
    "        \n",
    "    print(\"Done normalizing data\")\n",
    "        \n",
    "    print(f\"Fitting {modelType} model #{iteration}...\")\n",
    "    model = clf.fit(X_train_normalized, y_train)\n",
    "    print(\"Done fitting model\")\n",
    "    \n",
    "    print(f\"Computing results metrics for {modelType} model #{iteration}...\")\n",
    "    performanceDict = utils.performance_report(model, modelType, reportKey, iteration, X_train_normalized, X_test_normalized, y_train, y_test)\n",
    "    print(\"Done computing results metrics\\n\")\n",
    "\n",
    "    return performanceDict\n",
    "\n",
    "def parallel_model(df, modelType, reportKey, normalize, paramGrid, dataFile, ROI, heuristic=None):\n",
    "    print(f\"\\n======================Running {modelType} with the following parameters======================\\nNormalization: {normalize.__name__}\\nParam Grid: {paramGrid}\\nData: {dataFile}\\nROI: {ROI}\")\n",
    "\n",
    "    performance = []\n",
    "    if not os.path.isdir(modelType):\n",
    "        os.mkdir(modelType)\n",
    "\n",
    "    X = df.values\n",
    "    y = utils.convert_Y(X[:, -1])\n",
    "    columns = df.columns\n",
    "    \n",
    "    # Setup CV\n",
    "    cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=3, random_state=42)\n",
    "\n",
    "    # Define model type\n",
    "    if modelType == \"SVM\":\n",
    "        clf = GridSearchCV(SVC(random_state=0), paramGrid)\n",
    "    elif modelType == \"RF\":\n",
    "        clf = GridSearchCV(RandomForestClassifier(random_state=0, n_jobs = -1), paramGrid)\n",
    "    elif modelType == \"LR\":\n",
    "        clf = GridSearchCV(LogisticRegression(random_state=0), paramGrid)\n",
    "    \n",
    "    output = Parallel(n_jobs=-1)(delayed(train)(clf, train_index, test_index, X, y, normalize, columns, modelType, reportKey, iteration) for iteration, (train_index, test_index) in enumerate(cv.split(X, y)))\n",
    "\n",
    "    performance.append(output)\n",
    "\n",
    "    with open(f\"{modelType}/{reportKey}_report.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(performance, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    return performance"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03eb3d269ffa8480b6c622a58387450f74b2b472a591e6bfb46288b74805594b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
